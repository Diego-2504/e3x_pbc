{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12252498",
      "metadata": {
        "id": "12252498"
      },
      "source": [
        "# MD17: Graphene Prueba (force field construction)\n",
        "Prueba 2 para force field de grafeno. Funciones de ASE de neighbor_list. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "sWrM9dvX-dMg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWrM9dvX-dMg",
        "outputId": "ab24656e-7c7f-480a-e893-734caaf8be73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: e3x in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (1.0.2)\n",
            "Requirement already satisfied: absl-py in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (2.1.0)\n",
            "Requirement already satisfied: etils[epath] in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (1.5.2)\n",
            "Requirement already satisfied: flax in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (0.8.5)\n",
            "Requirement already satisfied: jax in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (0.4.30)\n",
            "Requirement already satisfied: jaxtyping in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (0.2.31)\n",
            "Requirement already satisfied: more_itertools in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (10.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (2.0.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from e3x) (1.12.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from etils[epath]->e3x) (2024.6.1)\n",
            "Requirement already satisfied: importlib_resources in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from etils[epath]->e3x) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from etils[epath]->e3x) (4.12.2)\n",
            "Requirement already satisfied: zipp in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from etils[epath]->e3x) (3.19.2)\n",
            "Requirement already satisfied: msgpack in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from flax->e3x) (1.0.8)\n",
            "Requirement already satisfied: optax in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from flax->e3x) (0.2.2)\n",
            "Requirement already satisfied: orbax-checkpoint in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from flax->e3x) (0.5.20)\n",
            "Requirement already satisfied: tensorstore in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from flax->e3x) (0.1.63)\n",
            "Requirement already satisfied: rich>=11.1 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from flax->e3x) (13.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from flax->e3x) (6.0.1)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from jax->e3x) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from jax->e3x) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from jax->e3x) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from jax->e3x) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from jax->e3x) (8.0.0)\n",
            "Requirement already satisfied: typeguard==2.13.3 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from jaxtyping->e3x) (2.13.3)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from sympy->e3x) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from rich>=11.1->flax->e3x) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from rich>=11.1->flax->e3x) (2.18.0)\n",
            "Requirement already satisfied: chex>=0.1.86 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from optax->flax->e3x) (0.1.86)\n",
            "Requirement already satisfied: nest_asyncio in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from orbax-checkpoint->flax->e3x) (1.6.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from orbax-checkpoint->flax->e3x) (5.27.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from chex>=0.1.86->optax->flax->e3x) (0.12.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->e3x) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade e3x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "60bUUxifl3te",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60bUUxifl3te",
        "outputId": "b048dac8-16fb-43f7-aa08-17fe76a5135b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ase in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (3.23.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from ase) (2.0.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from ase) (1.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from ase) (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from matplotlib>=3.3.4->ase) (6.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.4->ase) (3.19.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\brian\\anaconda3\\envs\\ase\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->ase) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ase"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a28781a",
      "metadata": {},
      "source": [
        "Librerías a utilizar "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8qZRQgvql9E0",
      "metadata": {
        "id": "8qZRQgvql9E0"
      },
      "outputs": [],
      "source": [
        "from ase.io import read\n",
        "from ase.visualize import view\n",
        "from scipy import sparse\n",
        "from ase.build import molecule\n",
        "from ase.neighborlist import get_connectivity_matrix\n",
        "from ase.neighborlist import natural_cutoffs\n",
        "from ase.neighborlist import NeighborList\n",
        "from ase.neighborlist import neighbor_list\n",
        "import scipy.sparse\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "62391d8d",
      "metadata": {
        "id": "62391d8d"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import os\n",
        "import urllib.request\n",
        "import e3x\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "\n",
        "# Disable future warnings.\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08c7436d",
      "metadata": {
        "id": "08c7436d"
      },
      "source": [
        "Dataset de prueba (6 datos de trayectoria)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9UKJqPdY_xP0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UKJqPdY_xP0",
        "outputId": "2a65fbb5-fac4-4c21-f5ab-94d091f5c584"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['R', 'E', 'F', 'z']\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "filename = \"graphene_prueba.npz\"\n",
        "\n",
        "# Verifica si el archivo existe usando la ruta\n",
        "if os.path.exists(filename):\n",
        "    # Carga el contenido del archivo\n",
        "    data = np.load(filename)\n",
        "    # Ahora puedes trabajar con data\n",
        "    print(data.files)\n",
        "else:\n",
        "    print(f\"El archivo {filename} no existe.\")\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d33a80",
      "metadata": {},
      "source": [
        "Dataset weno "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4db773d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['E', 'name', 'F', 'lattice', 'theory', 'R', 'z', 'type', 'md5']\n"
          ]
        }
      ],
      "source": [
        "#filename = \"graphene_prueba.npz\"\n",
        "filename = 'Graphene_7x7_MD.DFT.MD.500K.PBE.SuperCell_7x7.01.DATA4231.npz'\n",
        "\n",
        "# Verifica si el archivo existe usando la ruta\n",
        "if os.path.exists(filename):\n",
        "    # Carga el contenido del archivo\n",
        "    data = np.load(filename)\n",
        "    # Ahora puedes trabajar con data\n",
        "    print(data.files)\n",
        "else:\n",
        "    print(f\"El archivo {filename} no existe.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0ec47e3",
      "metadata": {},
      "source": [
        "### Prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "096ba1c9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nimport numpy as np\\nd_prueba = np.load('Graphene_7x7_MD.DFT.MD.500K.PBE.SuperCell_7x7.01.DATA4231.npz')\\nprint('Graphene_7x7_MD.DFT.MD.500K.PBE.SuperCell_7x7.01.DATA4231.npz')\\n\\nprint(d_prueba.files)\\n\""
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import numpy as np\n",
        "d_prueba = np.load('Graphene_7x7_MD.DFT.MD.500K.PBE.SuperCell_7x7.01.DATA4231.npz')\n",
        "print('Graphene_7x7_MD.DFT.MD.500K.PBE.SuperCell_7x7.01.DATA4231.npz')\n",
        "\n",
        "print(d_prueba.files)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "qRvXAxVWqTti",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRvXAxVWqTti",
        "outputId": "98388e9d-a350-41b2-a2bf-875193fdaaea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Número de átomos: 98\n",
            "\n",
            "Símbolos de los átomos: ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
            "\n",
            "Posiciones de los átomos:\n",
            " [[-7.8600000e-03 -8.4140000e-03  2.8800000e-04]\n",
            " [ 1.2222860e+00  7.0220900e-01 -1.1800000e-04]\n",
            " [ 1.2212900e+00  2.1224790e+00  4.9900000e-04]\n",
            " [ 2.4521420e+00  2.8331030e+00  2.3130000e-03]\n",
            " [ 2.4517430e+00  4.2547390e+00  3.9840000e-03]\n",
            " [ 3.6796630e+00  4.9656220e+00  4.4930000e-03]\n",
            " [ 3.6794510e+00  6.3910510e+00  6.2420000e-03]\n",
            " [ 4.9087000e+00  7.1051160e+00  7.2520000e-03]\n",
            " [ 4.9125660e+00  8.5267020e+00  8.8580000e-03]\n",
            " [ 6.1468640e+00  9.2394420e+00  9.6970000e-03]\n",
            " [ 6.1485570e+00  1.0658171e+01  1.0465000e-02]\n",
            " [ 7.3799830e+00  1.1368695e+01  9.7900000e-03]\n",
            " [ 7.3799860e+00  1.2789677e+01  5.7230000e-03]\n",
            " [ 8.6105080e+00  1.3499066e+01  3.2740000e-03]\n",
            " [ 2.4547500e+00 -9.2800000e-03  1.9400000e-04]\n",
            " [ 3.6848060e+00  6.9954700e-01  3.7400000e-04]\n",
            " [ 3.6831310e+00  2.1220400e+00  1.8790000e-03]\n",
            " [ 4.9125530e+00  2.8301110e+00  2.1010000e-03]\n",
            " [ 4.9088380e+00  4.2515900e+00  3.7140000e-03]\n",
            " [ 6.1386390e+00  4.9615530e+00 -3.5260000e-03]\n",
            " [ 6.1382270e+00  6.3951170e+00 -1.8630000e-03]\n",
            " [ 7.3799800e+00  7.1122720e+00 -9.5300000e-04]\n",
            " [ 7.3799830e+00  8.5319110e+00  9.0450000e-03]\n",
            " [ 8.6131010e+00  9.2394430e+00  9.5700000e-03]\n",
            " [ 8.6114150e+00  1.0658162e+01  1.0326000e-02]\n",
            " [ 9.8440990e+00  1.1367804e+01  8.0160000e-03]\n",
            " [ 9.8430120e+00  1.2787585e+01  4.4970000e-03]\n",
            " [ 1.1073800e+01  1.3497651e+01  1.6740000e-03]\n",
            " [ 4.9159820e+00 -1.1241000e-02 -2.0000000e-04]\n",
            " [ 6.1487070e+00  6.9854900e-01  3.5500000e-04]\n",
            " [ 6.1471870e+00  2.1174230e+00  1.1790000e-03]\n",
            " [ 7.3799930e+00  2.8247800e+00  1.8950000e-03]\n",
            " [ 7.3800010e+00  4.2451220e+00 -4.5520000e-03]\n",
            " [ 8.6213140e+00  4.9615540e+00 -3.6680000e-03]\n",
            " [ 8.6217450e+00  6.3951060e+00 -1.9780000e-03]\n",
            " [ 9.8512640e+00  7.1051060e+00  7.0210000e-03]\n",
            " [ 9.8474070e+00  8.5266920e+00  8.6360000e-03]\n",
            " [ 1.1077030e+01  9.2346100e+00  8.8210000e-03]\n",
            " [ 1.1075275e+01  1.0656955e+01  7.5040000e-03]\n",
            " [ 1.2305400e+01  1.1365916e+01  3.8470000e-03]\n",
            " [ 1.2304973e+01  1.2786829e+01  1.4630000e-03]\n",
            " [ 1.3535840e+01  1.3497070e+01 -5.4500000e-04]\n",
            " [ 7.3799980e+00 -1.1928000e-02 -3.5900000e-04]\n",
            " [ 8.6112800e+00  6.9854300e-01  3.2000000e-04]\n",
            " [ 8.6127980e+00  2.1174210e+00  1.0940000e-03]\n",
            " [ 9.8474200e+00  2.8301150e+00  1.9010000e-03]\n",
            " [ 9.8511440e+00  4.2515830e+00  3.4670000e-03]\n",
            " [ 1.1080305e+01  4.9656170e+00  4.1640000e-03]\n",
            " [ 1.1080520e+01  6.3910520e+00  5.9240000e-03]\n",
            " [ 1.2308379e+01  7.1017580e+00  6.7170000e-03]\n",
            " [ 1.2308033e+01  8.5233870e+00  7.2860000e-03]\n",
            " [ 1.3538737e+01  9.2339420e+00  4.2670000e-03]\n",
            " [ 1.3537796e+01  1.0654261e+01  2.4320000e-03]\n",
            " [ 1.4767862e+01  1.1364821e+01 -3.8400000e-04]\n",
            " [ 1.4768226e+01  1.2785487e+01 -1.3240000e-03]\n",
            " [ 1.5998685e+01  1.3494717e+01 -1.5600000e-03]\n",
            " [ 9.8440070e+00 -1.1242000e-02 -2.4100000e-04]\n",
            " [ 1.1075178e+01  6.9954700e-01  2.6300000e-04]\n",
            " [ 1.1076854e+01  2.1220390e+00  1.6600000e-03]\n",
            " [ 1.2307831e+01  2.8331040e+00  2.0400000e-03]\n",
            " [ 1.2308229e+01  4.2547400e+00  3.6530000e-03]\n",
            " [ 1.3539277e+01  4.9673910e+00  3.4390000e-03]\n",
            " [ 1.3539344e+01  6.3890250e+00  4.6680000e-03]\n",
            " [ 1.4768286e+01  7.0998490e+00  3.1960000e-03]\n",
            " [ 1.4768274e+01  8.5229530e+00  2.6400000e-03]\n",
            " [ 1.5998689e+01  9.2329590e+00  1.2510000e-03]\n",
            " [ 1.5998687e+01  1.0654233e+01 -2.2700000e-04]\n",
            " [ 1.7229513e+01  1.1364822e+01 -2.9100000e-04]\n",
            " [ 1.7229148e+01  1.2785488e+01 -1.3180000e-03]\n",
            " [ 1.8461530e+01  1.3497069e+01 -5.9000000e-04]\n",
            " [ 1.2305235e+01 -9.2770000e-03  2.7000000e-05]\n",
            " [ 1.3537694e+01  7.0220900e-01 -3.4200000e-04]\n",
            " [ 1.3538692e+01  2.1224800e+00  3.0200000e-04]\n",
            " [ 1.4768202e+01  2.8334380e+00  3.2000000e-05]\n",
            " [ 1.4768234e+01  4.2565260e+00  1.4980000e-03]\n",
            " [ 1.5998687e+01  4.9673490e+00  1.7430000e-03]\n",
            " [ 1.5998687e+01  6.3889710e+00  2.4880000e-03]\n",
            " [ 1.7229084e+01  7.0998480e+00  3.3530000e-03]\n",
            " [ 1.7229099e+01  8.5229530e+00  2.7400000e-03]\n",
            " [ 1.8458638e+01  9.2339420e+00  4.4420000e-03]\n",
            " [ 1.8459578e+01  1.0654265e+01  2.5630000e-03]\n",
            " [ 1.9691969e+01  1.1365921e+01  3.9550000e-03]\n",
            " [ 1.9692398e+01  1.2786831e+01  1.4490000e-03]\n",
            " [ 2.0923568e+01  1.3497654e+01  1.6770000e-03]\n",
            " [ 1.4767843e+01 -8.4130000e-03  1.3500000e-04]\n",
            " [ 1.5998688e+01  7.0224200e-01 -5.8300000e-04]\n",
            " [ 1.5998688e+01  2.1234300e+00 -7.9100000e-04]\n",
            " [ 1.7229171e+01  2.8334360e+00  1.5500000e-04]\n",
            " [ 1.7229134e+01  4.2565250e+00  1.6520000e-03]\n",
            " [ 1.8458096e+01  4.9673910e+00  3.7210000e-03]\n",
            " [ 1.8458028e+01  6.3890250e+00  4.9260000e-03]\n",
            " [ 1.9688990e+01  7.1017590e+00  7.0280000e-03]\n",
            " [ 1.9689339e+01  8.5233930e+00  7.5550000e-03]\n",
            " [ 2.0920333e+01  9.2346180e+00  9.0900000e-03]\n",
            " [ 2.0922095e+01  1.0656961e+01  7.7190000e-03]\n",
            " [ 2.2153269e+01  1.1367807e+01  8.2330000e-03]\n",
            " [ 2.2154356e+01  1.2787591e+01  4.4940000e-03]\n",
            " [ 2.3386856e+01  1.3499066e+01  3.2440000e-03]]\n"
          ]
        }
      ],
      "source": [
        "graphene_idxs = read('geometry100.in')\n",
        "print(\"\\nNúmero de átomos:\", len(graphene_idxs))\n",
        "print(\"\\nSímbolos de los átomos:\", graphene_idxs.get_chemical_symbols())\n",
        "print(\"\\nPosiciones de los átomos:\\n\", graphene_idxs.get_positions())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c51cb73e",
      "metadata": {},
      "source": [
        "#### Info del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "NZI9lSrU2xcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZI9lSrU2xcd",
        "outputId": "66e5433e-dd15-40c1-c7bd-382f80b6cfbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El shape de la energía es: (4231, 1)\n",
            "\n",
            "El shape de las fuerzas son: (4231, 98, 3)\n",
            "\n",
            "El shape de las posiciones son: (4231, 98, 3)\n"
          ]
        }
      ],
      "source": [
        "data_graph = np.load(filename)\n",
        "E = data_graph['E']\n",
        "F = data_graph['F']\n",
        "R = data_graph['R']\n",
        "print('El shape de la energía es:', E.shape)\n",
        "print('\\nEl shape de las fuerzas son:', F.shape)\n",
        "print('\\nEl shape de las posiciones son:', R.shape)\n",
        "\n",
        "#print('\\n', R)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0jsC_YKCAI0E",
      "metadata": {
        "id": "0jsC_YKCAI0E"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9b48878a",
      "metadata": {
        "id": "9b48878a"
      },
      "source": [
        "Now we write a small helper function to prepare train and validation datasets. Apart from choosing subsets of the full dataset and converting the data to a different format, this function also subtracts the mean energy of the training set from all data points. This is a useful numerical trick: The energy of a molecule is often a very large number (around $-97 000$ kcal/mol for ethanol), but the relative energy between different conformations of the same molecule is usually much smaller (a few kcal/mol for ethanol). Since models are typically trained with single precision floats for efficiency, the large energy offset wastes precious numerical precision. For this reason, large offsets should be subtracted frow the raw data (typically stored in double precision) *before* converting to single precision. Note that subtracting arbitrary constants from the energy does not change physics (of course, the constant can also just be added back to the model predictions after training)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7ec584df",
      "metadata": {
        "id": "7ec584df"
      },
      "outputs": [],
      "source": [
        "def prepare_datasets(key, num_train, num_valid):\n",
        "  # Load the dataset.\n",
        "  dataset = np.load(filename)\n",
        "\n",
        "  # Make sure that the dataset contains enough entries.\n",
        "  num_data = len(dataset['E'])\n",
        "  num_draw = num_train + num_valid\n",
        "  if num_draw > num_data:\n",
        "    raise RuntimeError(\n",
        "      f'datasets only contains {num_data} points, requested num_train={num_train}, num_valid={num_valid}')\n",
        "\n",
        "  # Randomly draw train and validation sets from dataset.\n",
        "  choice = np.asarray(jax.random.choice(key, num_data, shape=(num_draw,), replace=False))\n",
        "  train_choice = choice[:num_train]\n",
        "  valid_choice = choice[num_train:]\n",
        "\n",
        "  # Determine mean energy of the training set.\n",
        "  mean_energy = np.mean(dataset['E'][train_choice])  # ~ -97000\n",
        "\n",
        "  # Collect and return train and validation sets.\n",
        "  train_data = dict(\n",
        "    energy=jnp.asarray(dataset['E'][train_choice, 0] - mean_energy),\n",
        "    forces=jnp.asarray(dataset['F'][train_choice]),\n",
        "    atomic_numbers=jnp.asarray(dataset['z']),\n",
        "    positions=jnp.asarray(dataset['R'][train_choice]),\n",
        "  )\n",
        "  valid_data = dict(\n",
        "    energy=jnp.asarray(dataset['E'][valid_choice, 0] - mean_energy),\n",
        "    forces=jnp.asarray(dataset['F'][valid_choice]),\n",
        "    atomic_numbers=jnp.asarray(dataset['z']),\n",
        "    positions=jnp.asarray(dataset['R'][valid_choice]),\n",
        "  )\n",
        "  return train_data, valid_data, mean_energy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae391d59",
      "metadata": {
        "id": "ae391d59"
      },
      "source": [
        "Next, we define a very simple message-passing neural network.\n",
        "\n",
        "Let's first describe the model inputs and outputs: Our model takes `atomic_numbers` of shape `(num_atoms,)` (encoding the atom types), `positions` of shape `(num_atoms, 3)`, and index lists `dst_idx` (destination index) and `src_idx` (source index), both of shape `(num_pairs,)`, as inputs. The `dst_idx` and `src_idx` index lists specify \"which atoms talk with each other\" during a message-pass. For example, for a molecule with three atoms, these index lists could be `dst_idx = [0, 0, 1, 1, 2, 2]` and `src_idx = [1, 2, 0, 2, 0, 1]`. This would mean that the \"destination atom\" at index 0 receives messages from the \"source atoms\" at indices 1 and 2, and so on. This input format allows the model to handle batches of molecules with different numbers of atoms *without needing any padding* (in this example, all molecules are ethanol, so this is not necessary, but it's useful in general for more complicated tasks). We simply concatenate the `atomic_numbers` and `positions` of all molecules in the batch (as if they were one big molecule) and specify the index lists such that atoms in different molecules of the batch do not \"talk to each other\". The only additional information we need is a structure `batch_segments` that tells the model which atoms belong to which molecule in the batch and the total `batch_size`. For example, a batch consisting of a H$_2$O and a N$_2$ molecule could be specified with `atomic_numbers = [1, 1, 8, 7, 7]`, `dst_idx = [0, 0, 1, 1, 2, 2, 3, 4]`, `src_idx = [1, 2, 0, 2, 0, 1, 4, 3]`, `batch_segments = [0, 0, 0, 1, 1]` (meaning the first three atoms belong to molecule `0`, the last two to molecule `1`), and `batch_size = 2`. The outputs of our model are the `energy` of shape `(batch_size,)` of every molecule in the batch and the `forces` of shape `(num_atoms, 3)` acting on each atom.\n",
        "\n",
        "Since `forces` are the negative gradient of the `energy` with respect to the atomic `positions`, the model only needs to predict `energy`, as `forces` can be derived with automatic differentiation. This has the additional advantage that the forces will be conservative, i.e. they will respect the physical principle of energy conservation. The energy prediction comprises the following steps:\n",
        "\n",
        "1. Calculate the displacement vectors $\\vec{r}_{ij}=\\vec{r}_{j}-\\vec{r}_{i}$, where $\\vec{r}_{i}$ and $\\vec{r}_{j}$ are the positions of atoms $i$ (destination) and $j$ (source), for all pairs $i,j$ specified by the index lists.\n",
        "\n",
        "2. Expand the displacement vectors in radial-spherical basis functions to featurize them. Note that the basis functions use a cutoff, so that they go to zero beyond a certain distance.\n",
        "\n",
        "3. Embed the atoms in feature space by assigning them to learnable embeddings (one for each element).\n",
        "\n",
        "4. Perform `num_iterations` feature refinements. Each iteration performs a message-pass and combines the message with the current features of each atom. These intermediate features are passed through an atom-wise two-layer MLP and added to the original features (residual connection).\n",
        "\n",
        "5. Predict atomic energy contributions by performing linear regression on the final (scalar) features of each atom. Each atom type/element has its own bias term.\n",
        "\n",
        "6. Sum the atomic energy contributions within each batch segment to obtain the energy for every molecule in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "92de0676",
      "metadata": {
        "id": "92de0676"
      },
      "outputs": [],
      "source": [
        "class MessagePassingModel(nn.Module):\n",
        "  features: int = 32\n",
        "  max_degree: int = 2\n",
        "  num_iterations: int = 3\n",
        "  num_basis_functions: int = 8\n",
        "  cutoff: float = 5.0\n",
        "  max_atomic_number: int = 118  # This is overkill for most applications.\n",
        "\n",
        "\n",
        "  def energy(self, atomic_numbers, positions, dst_idx, src_idx, batch_segments, batch_size):\n",
        "    # 1. Calculate displacement vectors.\n",
        "    positions_dst = e3x.ops.gather_dst(positions, dst_idx=dst_idx)\n",
        "    positions_src = e3x.ops.gather_src(positions, src_idx=src_idx)\n",
        "    displacements = positions_src - positions_dst  # Shape (num_pairs, 3).\n",
        "\n",
        "    # 2. Expand displacement vectors in basis functions.\n",
        "    basis = e3x.nn.basis(  # Shape (num_pairs, 1, (max_degree+1)**2, num_basis_functions).\n",
        "      displacements,\n",
        "      num=self.num_basis_functions,\n",
        "      max_degree=self.max_degree,\n",
        "      radial_fn=e3x.nn.reciprocal_bernstein,\n",
        "      cutoff_fn=functools.partial(e3x.nn.smooth_cutoff, cutoff=self.cutoff)\n",
        "    )\n",
        "\n",
        "    # 3. Embed atomic numbers in feature space, x has shape (num_atoms, 1, 1, features).\n",
        "    x = e3x.nn.Embed(num_embeddings=self.max_atomic_number+1, features=self.features)(atomic_numbers)\n",
        "\n",
        "    # 4. Perform iterations (message-passing + atom-wise refinement).\n",
        "    for i in range(self.num_iterations):\n",
        "      # Message-pass.\n",
        "      if i == self.num_iterations-1:  # Final iteration.\n",
        "        # Since we will only use scalar features after the final message-pass, we do not want to produce non-scalar\n",
        "        # features for efficiency reasons.\n",
        "        y = e3x.nn.MessagePass(max_degree=0, include_pseudotensors=False)(x, basis, dst_idx=dst_idx, src_idx=src_idx)\n",
        "        # After the final message pass, we can safely throw away all non-scalar features.\n",
        "        x = e3x.nn.change_max_degree_or_type(x, max_degree=0, include_pseudotensors=False)\n",
        "      else:\n",
        "        # In intermediate iterations, the message-pass should consider all possible coupling paths.\n",
        "        y = e3x.nn.MessagePass()(x, basis, dst_idx=dst_idx, src_idx=src_idx)\n",
        "      y = e3x.nn.add(x, y)\n",
        "\n",
        "      # Atom-wise refinement MLP.\n",
        "      y = e3x.nn.Dense(self.features)(y)\n",
        "      y = e3x.nn.silu(y)\n",
        "      y = e3x.nn.Dense(self.features, kernel_init=jax.nn.initializers.zeros)(y)\n",
        "\n",
        "      # Residual connection.\n",
        "      x = e3x.nn.add(x, y)\n",
        "\n",
        "    # 5. Predict atomic energies with an ordinary dense layer.\n",
        "    element_bias = self.param('element_bias', lambda rng, shape: jnp.zeros(shape), (self.max_atomic_number+1))\n",
        "    atomic_energies = nn.Dense(1, use_bias=False, kernel_init=jax.nn.initializers.zeros)(x)  # (..., Natoms, 1, 1, 1)\n",
        "    atomic_energies = jnp.squeeze(atomic_energies, axis=(-1, -2, -3))  # Squeeze last 3 dimensions.\n",
        "    atomic_energies += element_bias[atomic_numbers]\n",
        "\n",
        "    # 6. Sum atomic energies to obtain the total energy.\n",
        "    energy = jax.ops.segment_sum(atomic_energies, segment_ids=batch_segments, num_segments=batch_size)\n",
        "\n",
        "    # To be able to efficiently compute forces, our model should return a single output (instead of one for each\n",
        "    # molecule in the batch). Fortunately, since all atomic contributions only influence the energy in their own\n",
        "    # batch segment, we can simply sum the energy of all molecules in the batch to obtain a single proxy output\n",
        "    # to differentiate.\n",
        "    return -jnp.sum(energy), energy  # Forces are the negative gradient, hence the minus sign.\n",
        "\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, atomic_numbers, positions, dst_idx, src_idx, batch_segments=None, batch_size=None):\n",
        "    if batch_segments is None:\n",
        "      batch_segments = jnp.zeros_like(atomic_numbers)\n",
        "      batch_size = 1\n",
        "\n",
        "    # Since we want to also predict forces, i.e. the gradient of the energy w.r.t. positions (argument 1), we use\n",
        "    # jax.value_and_grad to create a function for predicting both energy and forces for us.\n",
        "    energy_and_forces = jax.value_and_grad(self.energy, argnums=1, has_aux=True)\n",
        "    (_, energy), forces = energy_and_forces(atomic_numbers, positions, dst_idx, src_idx, batch_segments, batch_size)\n",
        "\n",
        "    return energy, forces"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dccda3dc",
      "metadata": {
        "id": "dccda3dc"
      },
      "source": [
        "With our model in place, we now write a function to prepare a batch of molecules in the format described above. For this simple example, the source and destination index lists include all $N(N-1)$ pairwise combinations of $N$ atoms (without self-interactions). E3x contains helper functions, such as `sparse_pairwise_indices`, to construct such $O(N^2)$ index lists. This is fine for a small molecule like ethanol, but we can do better than $O(N^2)$ scaling, which becomes important for larger molecules. Recall that our message-passing model uses a cutoff when expanding displacement vectors in basis functions. While it doesn't hurt to include interactions beyond the cutoff in the index lists (they will simply contribute nothing to the message received by the destination atom), it is not very efficient to do so. In a real application, it would be better to construct the index lists using some spatial partitioning method, such that only interactions within the cutoff distance are included. With this trick, evaluating the message-passing model scales $O(NM)$, where $M \\ll N$ is the average number of atoms within the cutoff distance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mfyKHWpblXtp",
      "metadata": {
        "id": "mfyKHWpblXtp"
      },
      "source": [
        "### Parte del código donde se cambia las listas de idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d5996a79",
      "metadata": {},
      "outputs": [],
      "source": [
        "graphene_ref = read('geometry100.in')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3427ef21",
      "metadata": {
        "id": "3427ef21"
      },
      "outputs": [],
      "source": [
        "def prepare_batches(key, data, batch_size, cutoff_mol):\n",
        "  # Determine the number of training steps per epoch.\n",
        "  data_size = len(data['energy'])\n",
        "  steps_per_epoch = data_size//batch_size\n",
        "\n",
        "  # Draw random permutations for fetching batches from the train data.\n",
        "  perms = jax.random.permutation(key, data_size)\n",
        "  perms = perms[:steps_per_epoch * batch_size]  # Skip the last batch (if incomplete).\n",
        "  perms = perms.reshape((steps_per_epoch, batch_size))\n",
        "\n",
        "  # cambiar idx []\n",
        "  # Prepare entries that are identical for each batch.\n",
        "\n",
        "  num_atoms = len(data['atomic_numbers'])\n",
        "  batch_segments = jnp.repeat(jnp.arange(batch_size), num_atoms)\n",
        "  atomic_numbers = jnp.tile(data['atomic_numbers'], batch_size)\n",
        "  offsets = jnp.arange(batch_size) * num_atoms\n",
        "\n",
        "  # Nueva prueba de lista de vecinos, radio de corte definido\n",
        "\n",
        "  dst_idx, src_idx, distances_graph = neighbor_list('ijd', graphene_ref, cutoff_mol)\n",
        "\n",
        "  \"\"\"\"\n",
        "  # Construcción original de E3x:\n",
        "  dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(len(train_data['atomic_numbers']))\n",
        "\n",
        "  # Primera prueba de construcción con ase.naturalcutoffs\n",
        "  # Construcción de los pre idx's\n",
        "  cutoffs = natural_cutoffs(graphene_idxs)\n",
        "  neighbor_list = NeighborList(cutoffs, self_interaction=False, bothways=True)\n",
        "  neighbor_list.update(graphene_idxs)\n",
        "  matrix_graph_sparse = neighbor_list.get_connectivity_matrix()\n",
        "  matrix_graph_dense = scipy.sparse.csr_matrix.todense(matrix_graph_sparse)\n",
        "\n",
        "  # Creación de las etiquetas de los vecinos de cada átomo\n",
        "  nbrs_total =[]\n",
        "  j = 0\n",
        "  for j in range(len(matrix_graph_dense[:][:])):\n",
        "    nbrs=[]\n",
        "    nbrs = [i for i in range(len(matrix_graph_dense[:][:])) if matrix_graph_dense[j,i] == 1]\n",
        "    nbrs_total.append(nbrs)\n",
        "    j+=1\n",
        "\n",
        "  #Construcción de dst_idx\n",
        "  dst_idx = []\n",
        "  for j in range(len(nbrs_total)):\n",
        "    prueba_cl = [j for i in range(len(nbrs_total[j]))]\n",
        "    dst_idx.append(prueba_cl)\n",
        "  dst_idx = list(itertools.chain(*dst_idx))\n",
        "  dst_idx = jnp.array(dst_idx)\n",
        "\n",
        "  #Construcción de scr_idx\n",
        "  src_idx = list(itertools.chain(*nbrs_total))\n",
        "  src_idx = jnp.array(src_idx)\n",
        "  \"\"\"\n",
        "\n",
        "  # Prepare batches.\n",
        "\n",
        " # dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(num_atoms)\n",
        "  dst_idx = (dst_idx + offsets[:, None]).reshape(-1)\n",
        "  src_idx = (src_idx + offsets[:, None]).reshape(-1)\n",
        "\n",
        "  # Assemble and return batches.\n",
        "  return [\n",
        "    dict(\n",
        "        energy=data['energy'][perm],\n",
        "        forces=data['forces'][perm].reshape(-1, 3),\n",
        "        atomic_numbers=atomic_numbers,\n",
        "        positions=data['positions'][perm].reshape(-1, 3),\n",
        "        dst_idx=dst_idx,\n",
        "        src_idx=src_idx,\n",
        "        batch_segments = batch_segments,\n",
        "    )\n",
        "    for perm in perms\n",
        "  ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hrmi06Sena91",
      "metadata": {
        "id": "Hrmi06Sena91"
      },
      "source": [
        "##### Prueba (no parte de la NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "vslXtcZVPKXb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vslXtcZVPKXb",
        "outputId": "75805025-7f46-44d7-cfee-42b90a33c0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n"
          ]
        }
      ],
      "source": [
        "print(data_graph['z'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yQYgxaGVOBi6",
      "metadata": {
        "id": "yQYgxaGVOBi6"
      },
      "source": [
        "#### Prueba de las funciones anteriores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "NKc_nbGvOBCb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKc_nbGvOBCb",
        "outputId": "4bf69f59-ccb6-4aed-e3fe-d3fac39533fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n"
          ]
        }
      ],
      "source": [
        "num_atoms = len(data_graph['z'])\n",
        "batch_segments = jnp.repeat(jnp.arange(batch_size), num_atoms)\n",
        "atomic_numbers = jnp.tile(data_graph['z'], batch_size)\n",
        "offsets = jnp.arange(batch_size) * num_atoms\n",
        "\n",
        "#print(offsets)\n",
        "#print(atomic_numbers)\n",
        "print(batch_segments)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8267ce2",
      "metadata": {
        "id": "f8267ce2"
      },
      "source": [
        "Next, we define our loss function. As is common for regression tasks, we choose the $L_2$ (squared error) loss. Since we want to fit two different quantities at once (energy and forces), we simply add their respective losses together. We also add a weighting factor that allows us to tune the relative importance of the different loss terms. For convenience, we also define a function to compute the mean absolute errors, for keeping track of the model performance during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "42ade191",
      "metadata": {
        "id": "42ade191"
      },
      "outputs": [],
      "source": [
        "def mean_squared_loss(energy_prediction, energy_target, forces_prediction, forces_target, forces_weight):\n",
        "  energy_loss = jnp.mean(optax.l2_loss(energy_prediction, energy_target))\n",
        "  forces_loss = jnp.mean(optax.l2_loss(forces_prediction, forces_target))\n",
        "  return energy_loss + forces_weight * forces_loss\n",
        "\n",
        "def mean_absolute_error(prediction, target):\n",
        "  return jnp.mean(jnp.abs(prediction - target))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3464331",
      "metadata": {
        "id": "a3464331"
      },
      "source": [
        "Now that we have all the ingredients, we need to write some boilerplate for training models."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0I7ggSG2nG5n",
      "metadata": {
        "id": "0I7ggSG2nG5n"
      },
      "source": [
        "##### Otra sección para la construcción de las listas de idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "8e54eb5a",
      "metadata": {
        "id": "8e54eb5a"
      },
      "outputs": [],
      "source": [
        "@functools.partial(jax.jit, static_argnames=('model_apply', 'optimizer_update', 'batch_size'))\n",
        "def train_step(model_apply, optimizer_update, batch, batch_size, forces_weight, opt_state, params):\n",
        "  def loss_fn(params):\n",
        "    energy, forces = model_apply(\n",
        "      params,\n",
        "      atomic_numbers=batch['atomic_numbers'],\n",
        "      positions=batch['positions'],\n",
        "      dst_idx=batch['dst_idx'],\n",
        "      src_idx=batch['src_idx'],\n",
        "      batch_segments=batch['batch_segments'],\n",
        "      batch_size=batch_size\n",
        "    )\n",
        "    loss = mean_squared_loss(\n",
        "      energy_prediction=energy,\n",
        "      energy_target=batch['energy'],\n",
        "      forces_prediction=forces,\n",
        "      forces_target=batch['forces'],\n",
        "      forces_weight=forces_weight\n",
        "    )\n",
        "    return loss, (energy, forces)\n",
        "  (loss, (energy, forces)), grad = jax.value_and_grad(loss_fn, has_aux=True)(params)\n",
        "  updates, opt_state = optimizer_update(grad, opt_state, params)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  energy_mae = mean_absolute_error(energy, batch['energy'])\n",
        "  forces_mae = mean_absolute_error(forces, batch['forces'])\n",
        "  return params, opt_state, loss, energy_mae, forces_mae\n",
        "\n",
        "\n",
        "@functools.partial(jax.jit, static_argnames=('model_apply', 'batch_size'))\n",
        "def eval_step(model_apply, batch, batch_size, forces_weight, params):\n",
        "  dataset = np.load(filename)\n",
        "  energy, forces = model_apply(\n",
        "    params,\n",
        "    atomic_numbers=batch['atomic_numbers'],\n",
        "    positions=batch['positions'],\n",
        "    dst_idx=batch['dst_idx'],\n",
        "    src_idx=batch['src_idx'],\n",
        "    batch_segments=batch['batch_segments'],\n",
        "    batch_size=batch_size\n",
        "  )\n",
        "  loss = mean_squared_loss(\n",
        "    energy_prediction=energy,\n",
        "    energy_target=batch['energy'],\n",
        "    forces_prediction=forces,\n",
        "    forces_target=batch['forces'],\n",
        "    forces_weight=forces_weight\n",
        "  )\n",
        "  energy_mae = mean_absolute_error(energy, batch['energy'])\n",
        "  forces_mae = mean_absolute_error(forces, batch['forces'])\n",
        "  return loss, energy_mae, forces_mae\n",
        "\n",
        "\n",
        "def train_model(key, model, train_data, valid_data, num_epochs, learning_rate, forces_weight, batch_size, cutoff_mol):\n",
        "  # Initialize model parameters and optimizer state.\n",
        "  key, init_key = jax.random.split(key)\n",
        "  optimizer = optax.adam(learning_rate)\n",
        "  # Nueva prueba de lista de vecinos, radio de corte definido\n",
        "  dst_idx, src_idx, distances_graph = neighbor_list('ijd', graphene_ref, cutoff_mol )\n",
        "\n",
        "  \"\"\"\n",
        "  dst_idx, src_idx = e3x.ops.sparse_pairwise_indices(len(train_data['atomic_numbers']))\n",
        "\n",
        "  # Construcción de los pre idx's\n",
        "  cutoffs = natural_cutoffs(graphene_idxs)\n",
        "  neighbor_list = NeighborList(cutoffs, self_interaction=False, bothways=True)\n",
        "  neighbor_list.update(graphene_idxs)\n",
        "  matrix_graph_sparse = neighbor_list.get_connectivity_matrix()\n",
        "  matrix_graph_dense = scipy.sparse.csr_matrix.todense(matrix_graph_sparse)\n",
        "\n",
        "  # Creación de las etiquetas de los vecinos de cada átomo\n",
        "  nbrs_total =[]\n",
        "  j = 0\n",
        "  for j in range(len(matrix_graph_dense[:][:])):\n",
        "    nbrs=[]\n",
        "    nbrs = [i for i in range(len(matrix_graph_dense[:][:])) if matrix_graph_dense[j,i] == 1]\n",
        "    nbrs_total.append(nbrs)\n",
        "    j+=1\n",
        "\n",
        "  #Construcción de dst_idx\n",
        "  dst_idx = []\n",
        "  for j in range(len(nbrs_total)):\n",
        "    prueba_cl = [j for i in range(len(nbrs_total[j]))]\n",
        "    dst_idx.append(prueba_cl)\n",
        "  dst_idx = list(itertools.chain(*dst_idx))\n",
        "  dst_idx = jnp.array(dst_idx)\n",
        "\n",
        "  #Construcción de scr_idx\n",
        "  src_idx = list(itertools.chain(*nbrs_total))\n",
        "  src_idx = jnp.array(src_idx)\n",
        "  \"\"\"\n",
        "\n",
        "  params = model.init(init_key,\n",
        "    atomic_numbers=train_data['atomic_numbers'],\n",
        "    positions=train_data['positions'][0],\n",
        "    dst_idx=dst_idx,\n",
        "    src_idx=src_idx,\n",
        "  )\n",
        "  opt_state = optimizer.init(params)\n",
        "\n",
        "  # Batches for the validation set need to be prepared only once.\n",
        "  key, shuffle_key = jax.random.split(key)\n",
        "  valid_batches = prepare_batches(shuffle_key, valid_data, batch_size, cutoff_mol)\n",
        "\n",
        "  # Train for 'num_epochs' epochs.\n",
        "  for epoch in range(1, num_epochs + 1):\n",
        "    # Prepare batches.\n",
        "    key, shuffle_key = jax.random.split(key)\n",
        "    train_batches = prepare_batches(shuffle_key, train_data, batch_size, cutoff_mol)\n",
        "\n",
        "    # Loop over train batches.\n",
        "    train_loss = 0.0\n",
        "    train_energy_mae = 0.0\n",
        "    train_forces_mae = 0.0\n",
        "    for i, batch in enumerate(train_batches):\n",
        "      params, opt_state, loss, energy_mae, forces_mae = train_step(\n",
        "        model_apply=model.apply,\n",
        "        optimizer_update=optimizer.update,\n",
        "        batch=batch,\n",
        "        batch_size=batch_size,\n",
        "        forces_weight=forces_weight,\n",
        "        opt_state=opt_state,\n",
        "        params=params\n",
        "      )\n",
        "      train_loss += (loss - train_loss)/(i+1)\n",
        "      train_energy_mae += (energy_mae - train_energy_mae)/(i+1)\n",
        "      train_forces_mae += (forces_mae - train_forces_mae)/(i+1)\n",
        "\n",
        "    # Evaluate on validation set.\n",
        "    valid_loss = 0.0\n",
        "    valid_energy_mae = 0.0\n",
        "    valid_forces_mae = 0.0\n",
        "    for i, batch in enumerate(valid_batches):\n",
        "      loss, energy_mae, forces_mae = eval_step(\n",
        "        model_apply=model.apply,\n",
        "        batch=batch,\n",
        "        batch_size=batch_size,\n",
        "        forces_weight=forces_weight,\n",
        "        params=params\n",
        "      )\n",
        "      valid_loss += (loss - valid_loss)/(i+1)\n",
        "      valid_energy_mae += (energy_mae - valid_energy_mae)/(i+1)\n",
        "      valid_forces_mae += (forces_mae - valid_forces_mae)/(i+1)\n",
        "\n",
        "    # Print progress.\n",
        "    print(f\"epoch: {epoch: 3d}                    train:   valid:\")\n",
        "    print(f\"    loss [a.u.]             {train_loss : 8.3f} {valid_loss : 8.3f}\")\n",
        "    print(f\"    energy mae [kcal/mol]   {train_energy_mae: 8.3f} {valid_energy_mae: 8.3f}\")\n",
        "    print(f\"    forces mae [kcal/mol/Å] {train_forces_mae: 8.3f} {valid_forces_mae: 8.3f}\")\n",
        "\n",
        "\n",
        "  # Return final model parameters.\n",
        "  return params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sFiN3NjGovUp",
      "metadata": {
        "id": "sFiN3NjGovUp"
      },
      "source": [
        "##### Otra prueba (no correr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "GpkuF8Z8idbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpkuF8Z8idbc",
        "outputId": "5f1c2850-2903-4c6b-8544-e8c22faeaf16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0  0  0 ... 97 97 97]\n",
            "(9506,)\n",
            "(9506,)\n",
            "97.0\n"
          ]
        }
      ],
      "source": [
        "dst_idx_prueba, src_idx_prueba = e3x.ops.sparse_pairwise_indices(len(data_graph['z']))\n",
        "print(dst_idx_prueba)\n",
        "len(src_idx_prueba)\n",
        "print(dst_idx_prueba.shape)\n",
        "print(src_idx_prueba.shape)\n",
        "#print(type(dst_idx_prueba))\n",
        "#print(type(src_idx_prueba))\n",
        "print(9506/98)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "477e66ad",
      "metadata": {
        "id": "477e66ad"
      },
      "source": [
        "The last step before training the model is to define the hyperparamters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ea80b8a9",
      "metadata": {
        "id": "ea80b8a9"
      },
      "outputs": [],
      "source": [
        "# Model hyperparameters.\n",
        "features = 32\n",
        "max_degree = 1\n",
        "num_iterations = 5\n",
        "num_basis_functions = 16\n",
        "cutoff = 6.0\n",
        "cutoff_mol = 5.0\n",
        "\n",
        "# Training hyperparameters.\n",
        "num_train = 100\n",
        "num_valid = 50\n",
        "num_epochs = 10\n",
        "learning_rate = 0.002\n",
        "forces_weight = 1.0\n",
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VLPsDUBAwHUH",
      "metadata": {
        "id": "VLPsDUBAwHUH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8b9ed7f5",
      "metadata": {
        "id": "8b9ed7f5"
      },
      "source": [
        "Finally, we can train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "bfe80569",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfe80569",
        "outputId": "5812a67e-399a-45de-99af-5fc2fbdaba3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch:   1                    train:   valid:\n",
            "    loss [a.u.]              514.638  496.132\n",
            "    energy mae [kcal/mol]      9.789    9.164\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   2                    train:   valid:\n",
            "    loss [a.u.]              513.720  495.963\n",
            "    energy mae [kcal/mol]      9.866    9.055\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   3                    train:   valid:\n",
            "    loss [a.u.]              513.068  495.877\n",
            "    energy mae [kcal/mol]      9.669    9.061\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   4                    train:   valid:\n",
            "    loss [a.u.]              512.806  495.970\n",
            "    energy mae [kcal/mol]      9.715    9.054\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   5                    train:   valid:\n",
            "    loss [a.u.]              513.455  495.896\n",
            "    energy mae [kcal/mol]      9.700    9.059\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   6                    train:   valid:\n",
            "    loss [a.u.]              513.649  496.331\n",
            "    energy mae [kcal/mol]      9.721    9.052\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   7                    train:   valid:\n",
            "    loss [a.u.]              514.192  495.828\n",
            "    energy mae [kcal/mol]      9.765    9.071\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   8                    train:   valid:\n",
            "    loss [a.u.]              514.297  495.792\n",
            "    energy mae [kcal/mol]      9.896    9.082\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:   9                    train:   valid:\n",
            "    loss [a.u.]              515.446  496.247\n",
            "    energy mae [kcal/mol]      9.842    9.052\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n",
            "epoch:  10                    train:   valid:\n",
            "    loss [a.u.]              513.080  496.557\n",
            "    energy mae [kcal/mol]      9.664    9.052\n",
            "    forces mae [kcal/mol/Å]   22.723   22.826\n"
          ]
        }
      ],
      "source": [
        "# Create PRNGKeys.\n",
        "data_key, train_key = jax.random.split(jax.random.PRNGKey(0), 2)\n",
        "\n",
        "# Draw training and validation sets.\n",
        "train_data, valid_data, _ = prepare_datasets(data_key, num_train=num_train, num_valid=num_valid)\n",
        "\n",
        "# Create and train model.\n",
        "message_passing_model = MessagePassingModel(\n",
        "  features=features,\n",
        "  max_degree=max_degree,\n",
        "  num_iterations=num_iterations,\n",
        "  num_basis_functions=num_basis_functions,\n",
        "  cutoff=cutoff,\n",
        ")\n",
        "params = train_model(\n",
        "  key=train_key,\n",
        "  model=message_passing_model,\n",
        "  train_data=train_data,\n",
        "  valid_data=valid_data,\n",
        "  num_epochs=num_epochs,\n",
        "  learning_rate=learning_rate,\n",
        "  forces_weight=forces_weight,\n",
        "  batch_size=batch_size,\n",
        "  cutoff_mol=cutoff_mol\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
